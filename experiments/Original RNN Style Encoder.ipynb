{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab85a31f-a1f7-47b1-bcc2-e34fe3b52f04",
   "metadata": {},
   "source": [
    "# Train the original style encoder\n",
    "\n",
    "Contrastively, using bilinear similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb27b3-4c3b-43a8-a312-ffe31d13f0ae",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad730ae-a96e-45e5-8b15-059e8fcbf7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 17:41:47.193995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 17:41:50.326428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ss_vq_vae.models.vqvae_oneshot import Model\n",
    "import confugue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96846605-f076-4b46-ab8e-50e798b35e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"/mnt/vdb/model-original-no-style-pretraining-19-11-2023/config.yaml\"\n",
    "cfg = confugue.Configuration.from_yaml_file(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced5b726-804b-4c1f-b58a-7d67f77ba7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ss_vq_vae.nn.nn import ResidualWrapper\n",
    "from ss_vq_vae.nn.bilinear_similarity import BilinearSimilarity\n",
    "from torch import nn\n",
    "\n",
    "class StyleEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.style_encoder_1d = nn.Sequential(*cfg['model']['style_encoder_1d'].configure_list())\n",
    "        self.style_encoder_rnn = cfg['model']['style_encoder_rnn'].maybe_configure(nn.GRU, batch_first=True)\n",
    "        self.style_encoder_0d = nn.Sequential(*cfg['model']['style_encoder_0d'].configure_list())\n",
    "        \n",
    "    def forward(self, input, length):\n",
    "        encoded = self.style_encoder_1d(input)\n",
    "\n",
    "        # Mask positions corresponding to padding\n",
    "        length = (length // (input.shape[2] / encoded.shape[2])).to(torch.int)\n",
    "        mask = (torch.arange(encoded.shape[2], device=encoded.device) < length[:, None])[:, None, :]\n",
    "        encoded = encoded * mask\n",
    "\n",
    "        if self.style_encoder_rnn is not None:\n",
    "            encoded = encoded.transpose(1, 2)\n",
    "            encoded = nn.utils.rnn.pack_padded_sequence(\n",
    "                encoded, length.clamp(min=1).to('cpu'),\n",
    "                batch_first=True, enforce_sorted=False)\n",
    "            _, encoded = self.style_encoder_rnn(encoded)\n",
    "            # Get rid of layer dimension\n",
    "            encoded = encoded.transpose(0, 1).reshape(input.shape[0], -1)\n",
    "        else:\n",
    "            # Compute the Gram matrix, normalized by the length squared\n",
    "            encoded = encoded / mask.sum(dim=2, keepdim=True) + torch.finfo(encoded.dtype).eps\n",
    "            encoded = torch.matmul(encoded, encoded.transpose(1, 2))\n",
    "        encoded = encoded.reshape(encoded.shape[0], -1)\n",
    "\n",
    "        encoded = self.style_encoder_0d(encoded)\n",
    "\n",
    "        return encoded, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4710a244-b99d-484a-8c01-1b7d1f23990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_audio_data(samples):\n",
    "    filtered_batch = [sample for sample in samples if sample[0] is not None]\n",
    "    audio_names, anchors, positives = zip(*filtered_batch)\n",
    "\n",
    "    anchors = torch.stack([torch.tensor(x) for x in anchors])\n",
    "    positives = torch.stack([torch.tensor(x) for x in positives])\n",
    "\n",
    "    return audio_names, anchors, positives\n",
    "\n",
    "\n",
    "class LocalAudioset(Dataset):\n",
    "    def __init__(self, cfg, audio_folder=None, audio_paths=None, sample_len=96, sampling_rate=16000):\n",
    "        super(LocalAudioset, self).__init__()\n",
    "        if (audio_folder and audio_paths) or (not audio_folder and not audio_paths):\n",
    "            raise ValueError(\"You must set only one of the audio_folder/audio_paths\")\n",
    "        if audio_folder:\n",
    "            self.audio_paths = [os.path.join(audio_folder, filename) for filename in os.listdir(audio_folder) if filename.endswith('.wav')]\n",
    "        elif audio_paths:\n",
    "            with open(audio_paths, 'r') as f:\n",
    "                self.audio_paths = f.read().split()\n",
    "        self.sample_len = sample_len\n",
    "        self.sr = sampling_rate\n",
    "        self.spec_fn = cfg['spectrogram'].bind(librosa.stft)\n",
    "        \n",
    "    def preprocess_audio(self, audio_path):\n",
    "        audio, _ = librosa.load(audio_path, sr=self.sr)\n",
    "        if len(audio) == 0:\n",
    "            audio = np.zeros(shape=[1], dtype=audio.dtype)\n",
    "        return np.log1p(np.abs(self.spec_fn(y=audio)))\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        audio_path = self.audio_paths[ix]\n",
    "\n",
    "        audio = self.preprocess_audio(audio_path)\n",
    "        # If the audio clip is too short, pad it with zeros\n",
    "        if audio.shape[1] < self.sample_len:\n",
    "            padding = self.sample_len - audio.shape[1] + 50\n",
    "            audio = np.pad(audio, ((0, 0), (0, padding)), mode='constant')\n",
    "\n",
    "        try:\n",
    "            anchor_begin, positive_begin = np.random.randint(0, audio.shape[1] - self.sample_len, size=2)\n",
    "            anchor = audio[:, anchor_begin:anchor_begin + self.sample_len]\n",
    "            positive = audio[:, positive_begin:positive_begin + self.sample_len]\n",
    "        except Exception as e:\n",
    "            print(audio.shape[1], self.sample_len, audio_path)\n",
    "            raise e\n",
    "        return audio_path, anchor, positive\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88524eee-5fdc-41da-9e86-a98d28654f2a",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac8c08f-6833-4efe-b79c-67979cca11b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StyleEncoder(\n",
       "  (style_encoder_1d): Sequential(\n",
       "    (0): Conv1d(1025, 1024, kernel_size=(4,), stride=(2,))\n",
       "    (1): ResidualWrapper(\n",
       "      (module): Sequential(\n",
       "        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (style_encoder_rnn): GRU(1024, 1024, batch_first=True)\n",
       "  (style_encoder_0d): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_encoder = StyleEncoder(cfg)\n",
    "style_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c40b70c-deb1-4ddb-9db3-5bd3aa08a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audios_path = \"/mnt/vdb/audioset-large/train_without_violin_bowed_list.txt\"\n",
    "valid_audios_folder = \"/mnt/vdb/audioset-large/valid_wav_16k\"\n",
    "output_path = \"/mnt/vdb/run-contrastive-original-without-violin-bowed-21-11-2023\"\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "no_of_epochs = 500\n",
    "# TODO: dodaj poniżej config device\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f585d9f4-a4d3-47d1-ba04-df51d7e4d958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:po9fw3x6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6be766f3064219a8a2869815bf1e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.310387…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-firebrand-7</strong> at: <a href='https://wandb.ai/wojtekk23/audio_model_training/runs/po9fw3x6' target=\"_blank\">https://wandb.ai/wojtekk23/audio_model_training/runs/po9fw3x6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231121_175146-po9fw3x6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:po9fw3x6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c4f656e2f347f5ab94cea37dc0d787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016671530466665748, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/ss-vq-vae/experiments/wandb/run-20231121_175206-3vxzpzdn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wojtekk23/audio_model_training/runs/3vxzpzdn' target=\"_blank\">ancient-microwave-8</a></strong> to <a href='https://wandb.ai/wojtekk23/audio_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wojtekk23/audio_model_training' target=\"_blank\">https://wandb.ai/wojtekk23/audio_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wojtekk23/audio_model_training/runs/3vxzpzdn' target=\"_blank\">https://wandb.ai/wojtekk23/audio_model_training/runs/3vxzpzdn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "145it [00:50,  3.45it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "232it [01:16,  5.02it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:39,  3.06it/s]\n",
      "4it [00:02,  1.99it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:11,  2.36it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:46,  2.63it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "145it [00:43,  5.00it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "227it [01:06,  5.86it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "1it [00:01,  1.64s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "31it [00:11,  3.07it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:39,  2.83it/s]\n",
      "141it [00:42,  5.32it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "235it [01:08,  5.01it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.50it/s]\n",
      "4it [00:02,  2.00it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "33it [00:11,  3.40it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:43,  2.71it/s]\n",
      "145it [00:43,  5.79it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "225it [01:06,  6.29it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.50it/s]\n",
      "1it [00:01,  1.61s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "31it [00:13,  2.50it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:45,  2.67it/s]\n",
      "142it [00:43,  3.12it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "229it [01:07,  2.86it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "4it [00:02,  2.01it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:11,  3.21it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:43,  2.71it/s]\n",
      "143it [00:43,  5.16it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "223it [01:06,  4.79it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.50it/s]\n",
      "1it [00:01,  1.63s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "32it [00:10,  4.34it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:37,  2.88it/s]\n",
      "147it [00:44,  5.24it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "228it [01:07,  5.23it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "4it [00:02,  2.05it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "32it [00:12,  3.41it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:48,  2.60it/s]\n",
      "143it [00:43,  4.99it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "227it [01:07,  5.06it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "1it [00:01,  1.62s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:10,  3.26it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:33,  3.00it/s]\n",
      "143it [00:43,  4.88it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "227it [01:06,  5.34it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "1it [00:01,  1.77s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "25it [00:10,  2.45it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:45,  2.66it/s]\n",
      "139it [00:42,  2.86it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "229it [01:07,  4.98it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "1it [00:01,  1.62s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.41it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:41,  2.77it/s]\n",
      "137it [00:42,  1.74it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "231it [01:07,  5.63it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "4it [00:02,  2.00it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:11,  3.31it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:44,  2.69it/s]\n",
      "147it [00:44,  3.83it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "225it [01:05,  3.44it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "4it [00:02,  2.04it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:11,  2.75it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:36,  2.91it/s]\n",
      "140it [00:42,  6.67it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "229it [01:06,  6.28it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.48it/s]\n",
      "1it [00:01,  1.60s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "30it [00:12,  2.37it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.74it/s]\n",
      "142it [00:42,  4.84it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "234it [01:08,  5.05it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "4it [00:02,  2.08it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:11,  3.26it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:38,  2.85it/s]\n",
      "141it [00:43,  2.50it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "224it [01:05,  6.23it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.49it/s]\n",
      "1it [00:02,  2.06s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.83it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:36,  2.91it/s]\n",
      "143it [00:42,  4.49it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "233it [01:08,  3.75it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.48it/s]\n",
      "1it [00:01,  1.60s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "27it [00:10,  2.58it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:34,  2.96it/s]\n",
      "141it [00:42,  5.71it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "227it [01:06,  6.33it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.50it/s]\n",
      "3it [00:02,  1.49it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:10,  3.41it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:46,  2.64it/s]\n",
      "141it [00:43,  4.17it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "224it [01:06,  3.98it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:28,  3.47it/s]\n",
      "4it [00:02,  2.04it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "33it [00:12,  3.17it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:46,  2.63it/s]\n",
      "149it [00:45,  3.45it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "231it [01:07,  5.85it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.48it/s]\n",
      "1it [00:01,  1.58s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "34it [00:11,  4.39it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:37,  2.89it/s]\n",
      "142it [00:42,  4.60it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "234it [01:08,  5.72it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.50it/s]\n",
      "4it [00:02,  2.05it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "30it [00:11,  2.76it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:33,  3.02it/s]\n",
      "148it [00:44,  6.27it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "235it [01:08,  4.19it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:28,  3.48it/s]\n",
      "1it [00:01,  1.60s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "34it [00:12,  3.45it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:44,  2.70it/s]\n",
      "146it [00:44,  3.92it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "227it [01:06,  4.50it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [01:27,  3.50it/s]\n",
      "3it [00:02,  1.49it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:11,  2.43it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:44,  2.68it/s]\n",
      "145it [00:43,  4.60it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "171it [00:50,  3.36it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m positives_lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor([positive\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m positive \u001b[38;5;129;01min\u001b[39;00m positives], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 66\u001b[0m y_anchors, _ \u001b[38;5;241m=\u001b[39m \u001b[43mstyle_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m y_positives, _ \u001b[38;5;241m=\u001b[39m style_encoder(positives, positives_lengths)\n\u001b[1;32m     69\u001b[0m similarities \u001b[38;5;241m=\u001b[39m bilinear_similarity(y_anchors, y_positives)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m, in \u001b[0;36mStyleEncoder.forward\u001b[0;34m(self, input, length)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle_encoder_rnn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m encoded\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     22\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(\n\u001b[0;32m---> 23\u001b[0m         encoded, \u001b[43mlength\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclamp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     24\u001b[0m         batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, enforce_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m     _, encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstyle_encoder_rnn(encoded)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Get rid of layer dimension\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "wandb.init(project='audio_model_training', config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": no_of_epochs,\n",
    "    \"train_audios_path\": train_audios_path,\n",
    "    \"valid_audios_path\": valid_audios_folder,\n",
    "    \"output_path\": output_path\n",
    "})\n",
    "\n",
    "# make sure the output directory exists\n",
    "if not os.path.exists(wandb.config.output_path):\n",
    "    os.makedirs(wandb.config.output_path)\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "train_dataset = LocalAudioset(cfg, audio_paths=train_audios_path)\n",
    "valid_dataset = LocalAudioset(cfg, audio_folder=valid_audios_folder)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,  # Accessing values via config\n",
    "    num_workers=8,\n",
    "    collate_fn=collate_audio_data\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_audio_data\n",
    ")\n",
    "\n",
    "bilinear_similarity = BilinearSimilarity(cfg['model']['style_encoder_rnn']['hidden_size'].get())\n",
    "bilinear_similarity.cuda()\n",
    "bilinear_similarity.train()\n",
    "\n",
    "style_encoder.cuda()\n",
    "style_encoder.train()\n",
    "\n",
    "optimizer = AdamW([{'params': style_encoder.parameters()}, {'params': bilinear_similarity.parameters()}], \n",
    "                  lr=config.learning_rate)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "step = 0\n",
    "for epoch in range(config.epochs):\n",
    "    style_encoder.train()\n",
    "    bilinear_similarity.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for ix, batch in tqdm(enumerate(train_loader)):\n",
    "        step += 1\n",
    "        audio_names, anchors, positives = batch\n",
    "        n_batch = anchors.shape[0]\n",
    "        anchors = anchors.cuda()\n",
    "        positives = positives.cuda()\n",
    "        anchors_lengths = torch.as_tensor([anchor.shape[1] for anchor in anchors], device='cuda')\n",
    "        positives_lengths = torch.as_tensor([positive.shape[1] for positive in positives], device='cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_anchors, _ = style_encoder(anchors, anchors_lengths)\n",
    "        y_positives, _ = style_encoder(positives, positives_lengths)\n",
    "        \n",
    "        similarities = bilinear_similarity(y_anchors, y_positives)\n",
    "        loss = cross_entropy(similarities, torch.arange(n_batch).cuda())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({'train_loss': loss.item()}, step=step)\n",
    "    \n",
    "    # Validation loop\n",
    "    style_encoder.eval()\n",
    "    bilinear_similarity.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ix, batch in tqdm(enumerate(valid_loader)):\n",
    "            audio_names, anchors, positives = batch\n",
    "            n_batch = anchors.shape[0]\n",
    "            anchors = anchors.cuda()\n",
    "            positives = positives.cuda()\n",
    "            anchors_lengths = torch.as_tensor([anchor.shape[1] for anchor in anchors], device='cuda')\n",
    "            positives_lengths = torch.as_tensor([positive.shape[1] for positive in positives], device='cuda')\n",
    "            \n",
    "            y_anchors, _ = style_encoder(anchors, anchors_lengths)\n",
    "            y_positives, _ = style_encoder(positives, positives_lengths)\n",
    "\n",
    "            similarities = bilinear_similarity(y_anchors, y_positives)\n",
    "            loss = cross_entropy(similarities, torch.arange(n_batch).cuda())\n",
    "\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    wandb.log({'val_loss': epoch_val_loss / len(valid_loader)}, step=step)\n",
    "    \n",
    "    latest_checkpoint_path = os.path.join(config.output_path, 'style_encoder_latest.pth')\n",
    "    torch.save(style_encoder.state_dict(), latest_checkpoint_path)\n",
    "    wandb.save(latest_checkpoint_path)\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(style_encoder.state_dict(), 'style_encoder.pth')\n",
    "wandb.save('style_encoder.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8d0cd-a9b8-4011-80b0-4ba174a82324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
