{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab85a31f-a1f7-47b1-bcc2-e34fe3b52f04",
   "metadata": {},
   "source": [
    "# Train the RNN style metric model (Audioset)\n",
    "\n",
    "Contrastively, using bilinear similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb27b3-4c3b-43a8-a312-ffe31d13f0ae",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad730ae-a96e-45e5-8b15-059e8fcbf7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 16:59:00.625323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 16:59:01.375382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from ss_vq_vae.models.vqvae_oneshot import Model\n",
    "import confugue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96846605-f076-4b46-ab8e-50e798b35e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"/mnt/vdb/model-original-no-style-pretraining-19-11-2023/config.yaml\"\n",
    "cfg = confugue.Configuration.from_yaml_file(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ced5b726-804b-4c1f-b58a-7d67f77ba7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ss_vq_vae.nn.nn import ResidualWrapper\n",
    "from ss_vq_vae.nn.bilinear_similarity import BilinearSimilarity\n",
    "from torch import nn\n",
    "\n",
    "class StyleEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.style_encoder_1d = nn.Sequential(*cfg['model']['style_encoder_1d'].configure_list())\n",
    "        self.style_encoder_rnn = cfg['model']['style_encoder_rnn'].maybe_configure(nn.GRU, batch_first=True)\n",
    "        self.style_encoder_0d = nn.Sequential(*cfg['model']['style_encoder_0d'].configure_list())\n",
    "        \n",
    "    def forward(self, input, length):\n",
    "        encoded = self.style_encoder_1d(input)\n",
    "\n",
    "        # Mask positions corresponding to padding\n",
    "        length = (length // (input.shape[2] / encoded.shape[2])).to(torch.int)\n",
    "        mask = (torch.arange(encoded.shape[2], device=encoded.device) < length[:, None])[:, None, :]\n",
    "        encoded = encoded * mask\n",
    "\n",
    "        if self.style_encoder_rnn is not None:\n",
    "            encoded = encoded.transpose(1, 2)\n",
    "            encoded = nn.utils.rnn.pack_padded_sequence(\n",
    "                encoded, length.clamp(min=1).to('cpu'),\n",
    "                batch_first=True, enforce_sorted=False)\n",
    "            _, encoded = self.style_encoder_rnn(encoded)\n",
    "            # Get rid of layer dimension\n",
    "            encoded = encoded.transpose(0, 1).reshape(input.shape[0], -1)\n",
    "        else:\n",
    "            # Compute the Gram matrix, normalized by the length squared\n",
    "            encoded = encoded / mask.sum(dim=2, keepdim=True) + torch.finfo(encoded.dtype).eps\n",
    "            encoded = torch.matmul(encoded, encoded.transpose(1, 2))\n",
    "        encoded = encoded.reshape(encoded.shape[0], -1)\n",
    "\n",
    "        encoded = self.style_encoder_0d(encoded)\n",
    "\n",
    "        return encoded, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4710a244-b99d-484a-8c01-1b7d1f23990d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_audio_data(samples):\n",
    "    filtered_batch = [sample for sample in samples if sample[0] is not None]\n",
    "    audio_names, anchors, positives = zip(*filtered_batch)\n",
    "\n",
    "    anchors = torch.stack([torch.tensor(x) for x in anchors])\n",
    "    positives = torch.stack([torch.tensor(x) for x in positives])\n",
    "\n",
    "    return audio_names, anchors, positives\n",
    "\n",
    "\n",
    "class LocalAudioset(Dataset):\n",
    "    def __init__(self, cfg, audio_folder=None, audio_paths=None, sample_len=96, sampling_rate=16000):\n",
    "        super(LocalAudioset, self).__init__()\n",
    "        if (audio_folder and audio_paths) or (not audio_folder and not audio_paths):\n",
    "            raise ValueError(\"You must set only one of the audio_folder/audio_paths\")\n",
    "        if audio_folder:\n",
    "            self.audio_paths = [os.path.join(audio_folder, filename) for filename in os.listdir(audio_folder) if filename.endswith('.wav')]\n",
    "        elif audio_paths:\n",
    "            with open(audio_paths, 'r') as f:\n",
    "                self.audio_paths = f.read().split()\n",
    "        self.sample_len = sample_len\n",
    "        self.sr = sampling_rate\n",
    "        self.spec_fn = cfg['spectrogram'].bind(librosa.stft)\n",
    "        \n",
    "    def preprocess_audio(self, audio_path):\n",
    "        audio, _ = librosa.load(audio_path, sr=self.sr)\n",
    "        if len(audio) == 0:\n",
    "            audio = np.zeros(shape=[1], dtype=audio.dtype)\n",
    "        return np.log1p(np.abs(self.spec_fn(y=audio)))\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        audio_path = self.audio_paths[ix]\n",
    "\n",
    "        audio = self.preprocess_audio(audio_path)\n",
    "        # If the audio clip is too short, pad it with zeros\n",
    "        if audio.shape[1] < self.sample_len:\n",
    "            padding = self.sample_len - audio.shape[1] + 50\n",
    "            audio = np.pad(audio, ((0, 0), (0, padding)), mode='constant')\n",
    "\n",
    "        try:\n",
    "            anchor_begin, positive_begin = np.random.randint(0, audio.shape[1] - self.sample_len, size=2)\n",
    "            anchor = audio[:, anchor_begin:anchor_begin + self.sample_len]\n",
    "            positive = audio[:, positive_begin:positive_begin + self.sample_len]\n",
    "        except Exception as e:\n",
    "            print(audio.shape[1], self.sample_len, audio_path)\n",
    "            raise e\n",
    "        return audio_path, anchor, positive\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88524eee-5fdc-41da-9e86-a98d28654f2a",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac8c08f-6833-4efe-b79c-67979cca11b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StyleEncoder(\n",
       "  (style_encoder_1d): Sequential(\n",
       "    (0): Conv1d(1025, 1024, kernel_size=(4,), stride=(2,))\n",
       "    (1): ResidualWrapper(\n",
       "      (module): Sequential(\n",
       "        (0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): LeakyReLU(negative_slope=0.1)\n",
       "        (2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (style_encoder_rnn): GRU(1024, 1024, batch_first=True)\n",
       "  (style_encoder_0d): Sequential()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_encoder = StyleEncoder(cfg)\n",
    "style_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c40b70c-deb1-4ddb-9db3-5bd3aa08a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audios_path = \"/mnt/vdb/audioset-large/train_list.txt\"\n",
    "valid_audios_folder = \"/mnt/vdb/audioset-large/valid_wav_16k\"\n",
    "output_path = \"/mnt/vdb/run-contrastive-original-style-metric-08-07-2024\"\n",
    "\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "no_of_epochs = 500\n",
    "# TODO: dodaj poniÅ¼ej config device\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f585d9f4-a4d3-47d1-ba04-df51d7e4d958",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwojtekk23\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/user/ss-vq-vae/experiments/wandb/run-20240708_165904-06a2sexx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wojtekk23/original_style_metric_training/runs/06a2sexx' target=\"_blank\">glorious-shadow-2</a></strong> to <a href='https://wandb.ai/wojtekk23/original_style_metric_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wojtekk23/original_style_metric_training' target=\"_blank\">https://wandb.ai/wojtekk23/original_style_metric_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wojtekk23/original_style_metric_training/runs/06a2sexx' target=\"_blank\">https://wandb.ai/wojtekk23/original_style_metric_training/runs/06a2sexx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [00:27,  7.83it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "221it [00:40,  6.36it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.39it/s]\n",
      "1it [00:01,  1.25s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.68it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.73it/s]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
      "134it [00:25,  6.21it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "222it [00:42,  6.09it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:58,  5.24it/s]\n",
      "1it [00:02,  2.03s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "28it [00:10,  3.20it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:44,  2.69it/s]\n",
      "139it [00:24,  6.45it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "228it [00:41,  7.20it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:55,  5.49it/s]\n",
      "1it [00:01,  1.29s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "24it [00:06,  4.90it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:39,  2.83it/s]\n",
      "141it [00:25,  7.69it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "235it [00:42,  8.42it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:55,  5.53it/s]\n",
      "1it [00:02,  2.01s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.55it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:43,  2.70it/s]\n",
      "140it [00:21,  9.74it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "228it [00:37,  7.80it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:52,  5.82it/s]\n",
      "1it [00:01,  1.24s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.91it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.74it/s]\n",
      "141it [00:19, 10.74it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "228it [00:31, 10.00it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:42,  7.19it/s]\n",
      "1it [00:01,  1.29s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.68it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.73it/s]\n",
      "137it [00:20,  9.39it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "223it [00:32,  8.65it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:42,  7.14it/s]\n",
      "1it [00:02,  2.04s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "25it [00:06,  5.29it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:13,  3.82it/s]\n",
      "139it [00:25,  5.87it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "235it [00:43,  5.85it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.38it/s]\n",
      "1it [00:01,  1.21s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "31it [00:12,  2.70it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.73it/s]\n",
      "141it [00:25,  7.64it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "228it [00:42,  7.29it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.39it/s]\n",
      "1it [00:01,  1.26s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.65it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.73it/s]\n",
      "143it [00:27,  8.09it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "223it [00:39,  7.70it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:55,  5.51it/s]\n",
      "1it [00:01,  1.27s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "33it [00:06,  6.61it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [00:48,  5.82it/s]\n",
      "137it [00:25,  7.24it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "227it [00:42,  7.67it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.38it/s]\n",
      "1it [00:01,  1.25s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.66it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.74it/s]\n",
      "141it [00:26,  7.40it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "235it [00:43,  6.13it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.37it/s]\n",
      "1it [00:01,  1.29s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.66it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [00:57,  4.89it/s]\n",
      "138it [00:25,  7.48it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "225it [00:41,  6.09it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.40it/s]\n",
      "1it [00:02,  2.05s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "32it [00:12,  3.43it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:43,  2.71it/s]\n",
      "141it [00:23,  6.44it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "235it [00:41,  6.00it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:55,  5.56it/s]\n",
      "1it [00:01,  1.26s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "31it [00:12,  2.65it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:43,  2.72it/s]\n",
      "137it [00:26,  7.19it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "226it [00:42,  7.85it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:57,  5.37it/s]\n",
      "1it [00:01,  1.25s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "29it [00:05,  6.65it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [00:51,  5.43it/s]\n",
      "133it [00:25,  6.18it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "223it [00:42,  7.15it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:58,  5.24it/s]\n",
      "1it [00:01,  1.26s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:11,  2.64it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.75it/s]\n",
      "137it [00:25,  7.57it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "224it [00:42,  6.21it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:57,  5.36it/s]\n",
      "1it [00:02,  2.04s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "26it [00:10,  2.42it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.74it/s]\n",
      "135it [00:25,  7.26it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "232it [00:43,  7.85it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:58,  5.26it/s]\n",
      "1it [00:01,  1.25s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "29it [00:05,  5.53it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [00:57,  4.86it/s]\n",
      "146it [00:27,  6.09it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "226it [00:41,  6.15it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:56,  5.38it/s]\n",
      "1it [00:01,  1.22s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "31it [00:12,  2.70it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:42,  2.74it/s]\n",
      "145it [00:25,  7.36it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "231it [00:39,  7.69it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:52,  5.88it/s]\n",
      "1it [00:01,  1.32s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "29it [00:06,  5.73it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "281it [01:04,  4.33it/s]\n",
      "139it [00:23,  8.87it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "224it [00:37,  6.70it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "306it [00:49,  6.12it/s]\n",
      "1it [00:01,  1.33s/it]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "32it [00:08,  4.56it/s]/home/user/miniconda3/lib/python3.8/site-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1\n",
      "  warnings.warn(\n",
      "174it [00:40,  4.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m epoch_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ix, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(valid_loader)):\n\u001b[1;32m     84\u001b[0m         audio_names, anchors, positives \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     85\u001b[0m         n_batch \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/std.py:1185\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1182\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "wandb.init(project='original_style_metric_training', config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": no_of_epochs,\n",
    "    \"train_audios_path\": train_audios_path,\n",
    "    \"valid_audios_path\": valid_audios_folder,\n",
    "    \"output_path\": output_path\n",
    "})\n",
    "\n",
    "# make sure the output directory exists\n",
    "if not os.path.exists(wandb.config.output_path):\n",
    "    os.makedirs(wandb.config.output_path)\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "train_dataset = LocalAudioset(cfg, audio_paths=train_audios_path)\n",
    "valid_dataset = LocalAudioset(cfg, audio_folder=valid_audios_folder)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,  # Accessing values via config\n",
    "    num_workers=8,\n",
    "    collate_fn=collate_audio_data\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_audio_data\n",
    ")\n",
    "\n",
    "bilinear_similarity = BilinearSimilarity(cfg['model']['style_encoder_rnn']['hidden_size'].get())\n",
    "bilinear_similarity.cuda()\n",
    "bilinear_similarity.train()\n",
    "\n",
    "style_encoder.cuda()\n",
    "style_encoder.train()\n",
    "\n",
    "optimizer = AdamW([{'params': style_encoder.parameters()}, {'params': bilinear_similarity.parameters()}], \n",
    "                  lr=config.learning_rate)\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "step = 0\n",
    "for epoch in range(config.epochs):\n",
    "    style_encoder.train()\n",
    "    bilinear_similarity.train()\n",
    "    \n",
    "    # Training loop\n",
    "    for ix, batch in tqdm(enumerate(train_loader)):\n",
    "        step += 1\n",
    "        audio_names, anchors, positives = batch\n",
    "        n_batch = anchors.shape[0]\n",
    "        anchors = anchors.cuda()\n",
    "        positives = positives.cuda()\n",
    "        anchors_lengths = torch.as_tensor([anchor.shape[1] for anchor in anchors], device='cuda')\n",
    "        positives_lengths = torch.as_tensor([positive.shape[1] for positive in positives], device='cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_anchors, _ = style_encoder(anchors, anchors_lengths)\n",
    "        y_positives, _ = style_encoder(positives, positives_lengths)\n",
    "        \n",
    "        similarities = bilinear_similarity(y_anchors, y_positives)\n",
    "        loss = cross_entropy(similarities, torch.arange(n_batch).cuda())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        wandb.log({'train_loss': loss.item()}, step=step)\n",
    "    \n",
    "    # Validation loop\n",
    "    style_encoder.eval()\n",
    "    bilinear_similarity.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for ix, batch in tqdm(enumerate(valid_loader)):\n",
    "            audio_names, anchors, positives = batch\n",
    "            n_batch = anchors.shape[0]\n",
    "            anchors = anchors.cuda()\n",
    "            positives = positives.cuda()\n",
    "            anchors_lengths = torch.as_tensor([anchor.shape[1] for anchor in anchors], device='cuda')\n",
    "            positives_lengths = torch.as_tensor([positive.shape[1] for positive in positives], device='cuda')\n",
    "            \n",
    "            y_anchors, _ = style_encoder(anchors, anchors_lengths)\n",
    "            y_positives, _ = style_encoder(positives, positives_lengths)\n",
    "\n",
    "            similarities = bilinear_similarity(y_anchors, y_positives)\n",
    "            loss = cross_entropy(similarities, torch.arange(n_batch).cuda())\n",
    "\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    wandb.log({'val_loss': epoch_val_loss / len(valid_loader)}, step=step)\n",
    "    \n",
    "    latest_checkpoint_path = os.path.join(config.output_path, 'style_encoder_latest.pth')\n",
    "    torch.save(style_encoder.state_dict(), latest_checkpoint_path)\n",
    "    torch.save(bilinear_similarity.state_dict(), os.path.join(config.output_path, 'bilinear_similarity_latest.pth'))\n",
    "    wandb.save(latest_checkpoint_path)\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(style_encoder.state_dict(), 'style_encoder.pth')\n",
    "wandb.save('style_encoder.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8d0cd-a9b8-4011-80b0-4ba174a82324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
